{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "Total data-id attributes found: 7120\n",
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "uploaded * sheet name *search_output* in sheet_id *1AZVMYH_qgty_0IT8TtmsCZypWisTn4yOHdCM_JdghG8\n",
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashy\\AppData\\Local\\Temp\\ipykernel_4872\\3588460298.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Unique Values List']=df['Unique Values List'].apply(clip_to_max)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "uploaded * sheet name *research_of_attributes* in sheet_id *1AZVMYH_qgty_0IT8TtmsCZypWisTn4yOHdCM_JdghG8\n"
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "from urllib.parse import urlencode\n",
    "from bs4 import BeautifulSoup\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import io\n",
    "from scrapper import flipkart_json_scrapper_with_all_specifications as fk_scrapper\n",
    "from piTask import general\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "# Create an instance of the UserAgent class\n",
    "ua = UserAgent()\n",
    "\n",
    "# Thread-local data to store per-thread HTTPSConnection\n",
    "thread_local = threading.local()\n",
    "output_sheet = '1AZVMYH_qgty_0IT8TtmsCZypWisTn4yOHdCM_JdghG8'\n",
    "\n",
    "def get_connection():\n",
    "    if not hasattr(thread_local, 'conn'):\n",
    "        thread_local.conn = http.client.HTTPSConnection(\"www.flipkart.com\", timeout=10)\n",
    "    return thread_local.conn\n",
    "\n",
    "def get_fsn(search, page):\n",
    "    params = {\n",
    "        'q': search,\n",
    "        'page': page\n",
    "    }\n",
    "    query_string = urlencode(params)\n",
    "    path = f\"/search?{query_string}\"\n",
    "    headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'Accept-Language': 'en-US,en;q=0.9,en-IN;q=0.8',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Cookie': 'T=TI171834590882700170348350689694114812841536586598665351035628902266; _pxvid=eb18d238-2a15-11ef-8332-14f84e743341; vw=1825; dpr=1; ULSN=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJjb29raWUiLCJhdWQiOiJmbGlwa2FydCIsImlzcyI6ImF1dGguZmxpcGthcnQuY29tIiwiY2xhaW1zIjp7ImdlbiI6IjIiLCJ1bmlxdWVJZCI6IlVVSTI0MDYyMDExNTY1MTc4NDNPSjZNUDgiLCJma0RldiI6bnVsbH0sImV4cCI6MTczNTM5NTI2MSwiaWF0IjoxNzE5NjE1MjYxLCJqdGkiOiI5ZDExMTY5Mi03Y2UzLTRhMWUtYTA1Yy00ODhhZmNjNGFlOTEifQ.zOExzRJ7a938XyR0l0YYDIJXAWZrdo-X_3CVzJ0Yllk; ud=2.u2YKt5hrZGXNxNErz_Q2VW8FPyxCcsau8k1QHbiRYvk1M2SDMWrqCY8MD3TmoSVYSxXjwN6aD6dCfcJOgYrZ0Kx92e6InzYfjmWi43c5YcrfEW4fi15IEDoyrFMOhg_J9hTN9FxdR8s8IDJK2MS6hYoh9u_GswCVpF86xnSr1IAIE3GYBd_LDvGSC_6jDIKSY5MeCZYhN6VFehjLF7U8vZif2wMdXsOIGeNpZhzEHK0IDd4YmBulQQSaH2OO-MRI; _fbp=fb.1.1723806825233.442773842490427820; s_nr=1723806878808-Repeat; AMCV_55CFEDA0570C3FA17F000101%40AdobeOrg=-227196251%7CMCIDTS%7C19962%7CMCMID%7C77060089323537194633849373282035801268%7CMCAAMLH-1724411625%7C12%7CMCAAMB-1724663150%7C6G1ynYcLPuiQxYZrsz_pkqfLG9yMXBpb2zX5dvJdYQJzPXImdj0y%7CMCOPTOUT-1723814025s%7CNONE%7CMCAID%7CNONE; mp_9ea3bc9a23c575907407cf80efd56524_mixpanel=%7B%22distinct_id%22%3A%20%22ACC9644F91FB39448188106BA68C24709F8D%22%2C%22%24device_id%22%3A%20%221904f6797d98b5-08cc87a0a28c2b-4c657b58-1fa400-1904f6797dcaa3%22%2C%22%24initial_referrer%22%3A%20%22%24direct%22%2C%22%24initial_referring_domain%22%3A%20%22%24direct%22%2C%22%24user_id%22%3A%20%22ACC9644F91FB39448188106BA68C24709F8D%22%7D; _ga_0SJLGHBL81=GS1.1.1724810832.8.0.1724810832.0.0.0; _ga_TVF0VCMCT3=GS1.1.1724810832.8.0.1724810832.60.0.0; _ga=GA1.2.10499125.1718980240; _ga_2P94RMW04V=GS1.2.1725448195.1.0.1725448195.0.0.0; vh=956; AMCV_17EB401053DAF4840A490D4C%40AdobeOrg=-227196251%7CMCIDTS%7C20006%7CMCMID%7C52021146135361344382423900263871368379%7CMCAAMLH-1728625898%7C3%7CMCAAMB-1729057779%7C6G1ynYcLPuiQxYZrsz_pkqfLG9yMXBpb2zX5dvJdYQJzPXImdj0y%7CMCOPTOUT-1728460179s%7CNONE%7CMCAID%7CNONE; _gcl_au=1.1.680070548.1728456988; K-ACTION=null; at=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IjNhNzdlZTgxLTRjNWYtNGU5Ni04ZmRlLWM3YWMyYjVlOTA1NSJ9.eyJleHAiOjE3Mjg0OTA3ODIsImlhdCI6MTcyODQ4ODk4MiwiaXNzIjoia2V2bGFyIiwianRpIjoiM2FlZmUyNTYtZDA0Mi00MzNkLWI5NGQtMDg3MTg2ZDAxZmUyIiwidHlwZSI6IkFUIiwiZElkIjoiVEkxNzE4MzQ1OTA4ODI3MDAxNzAzNDgzNTA2ODk2OTQxMTQ4MTI4NDE1MzY1ODY1OTg2NjUzNTEwMzU2Mjg5MDIyNjYiLCJiSWQiOiJXSERQT0YiLCJrZXZJZCI6IlZJRUI0Q0QxMTVDNUZFNDNGNEFGNDUyMDgzNTg2QzQ1RjMiLCJ0SWQiOiJtYXBpIiwiZWFJZCI6IlVSalBra2w5SmNqVUs0U3E5NlpkMWN4UWMybWduaHNXV2tWa3FxNFhPZXg2THJjcnBFTmRvdz09IiwidnMiOiJMSSIsInoiOiJDSCIsIm0iOnRydWUsImdlbiI6NH0.U0i-Lv3G0HKMjt9cQc90O_DaEXfORzMViDhmAA57Lgs; rt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IjhlM2ZhMGE3LTJmZDMtNGNiMi05MWRjLTZlNTMxOGU1YTkxZiJ9.eyJleHAiOjE3NDQyMTM3ODIsImlhdCI6MTcyODQ4ODk4MiwiaXNzIjoia2V2bGFyIiwianRpIjoiZjhkYjk1NzQtMDkyNy00MTE4LTk1NjUtYTFlNDNkYzA2NTFhIiwidHlwZSI6IlJUIiwiZElkIjoiVEkxNzE4MzQ1OTA4ODI3MDAxNzAzNDgzNTA2ODk2OTQxMTQ4MTI4NDE1MzY1ODY1OTg2NjUzNTEwMzU2Mjg5MDIyNjYiLCJiSWQiOiJXSERQT0YiLCJrZXZJZCI6IlZJRUI0Q0QxMTVDNUZFNDNGNEFGNDUyMDgzNTg2QzQ1RjMiLCJ0SWQiOiJtYXBpIiwibSI6eyJ0eXBlIjoibiJ9LCJ2IjoiRVVaMFhPIn0.RnavdI1eoACinVlH0JYjSgLqPK5ms-qbtI5t_N6bVCk; vd=VIEB4CD115C5FE43F4AF452083586C45F3-1718864841660-60.1728488982.1728488982.159438843; Network-Type=4g; qH=418696e663e903e6; s_sq=flipkart-prd%3D%2526pid%253Dwww.flipkart.com%25253Asearch%2526pidt%253D1%2526oid%253Dhttps%25253A%25252F%25252Fwww.flipkart.com%25252F%2526ot%253DA; fonts-loaded=en_loaded; isH2EnabledBandwidth=true; h2NetworkBandwidth=9; gpv_pn=HomePage; gpv_pn_t=FLIPKART%3AHomePage; S=d1t10Nz8/Pz8pbD8/Pxo/fD8iWFuBy3O0csqf8iMaXX03mKhIzCKaDVTPJZQGnlIVodlGW5eg0Gtlbq1EU++yHoVQ/g==; SN=VIEB4CD115C5FE43F4AF452083586C45F3.TOKBA2590E72609430E8A8F39668EA3CEE4.1728488998999.LI',\n",
    "    'Referer': 'https://www.flipkart.com/search?q=bluetooth+earphone&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&p%5B%5D=facets.price_range.from%3D1000&p%5B%5D=facets.price_range.to%3D1500',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': ua.random,\n",
    "    'sec-ch-ua': '\"Microsoft Edge\";v=\"129\", \"Not=A?Brand\";v=\"8\", \"Chromium\";v=\"129\"',\n",
    "    'sec-ch-ua-arch': '\"x86\"',\n",
    "    'sec-ch-ua-full-version': '\"129.0.2792.79\"',\n",
    "    'sec-ch-ua-full-version-list': '\"Microsoft Edge\";v=\"129.0.2792.79\", \"Not=A?Brand\";v=\"8.0.0.0\", \"Chromium\";v=\"129.0.6668.90\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-model': '\"\"',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-ch-ua-platform-version': '\"15.0.0\"'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        conn.request(\"GET\", path, headers=headers)\n",
    "        res = conn.getresponse()\n",
    "        if res.status != 200:\n",
    "            print(f\"Error fetching page {page} for search '{search}': {res.status} {res.reason}\")\n",
    "            res.close()\n",
    "            return []\n",
    "        data = res.read()\n",
    "        res.close()\n",
    "\n",
    "        # Handle gzip encoding if present\n",
    "        encoding = res.getheader('Content-Encoding')\n",
    "        if encoding == 'gzip':\n",
    "            buf = io.BytesIO(data)\n",
    "            f = gzip.GzipFile(fileobj=buf)\n",
    "            data = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "        elements_with_data_id = soup.find_all(attrs={'data-id': True})\n",
    "        data_list = []\n",
    "        for position, element in enumerate(elements_with_data_id, start=1):\n",
    "            data_id = element['data-id']\n",
    "            data_list.append({\n",
    "                'search_query': search,\n",
    "                'position': position,\n",
    "                'page_no': page,\n",
    "                'data_id': data_id\n",
    "            })\n",
    "\n",
    "        return data_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in get_fsn for search '{search}' page {page}: {e}\")\n",
    "        return []\n",
    "\n",
    "def collect_all_data_ids(search_queries, start_page, end_page):\n",
    "    all_data = []\n",
    "    tasks = [(search, page) for search in search_queries for page in range(start_page, end_page + 1)]\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        future_to_task = {executor.submit(get_fsn, search, page): (search, page) for (search, page) in tasks}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_task):\n",
    "            search, page = future_to_task[future]\n",
    "            try:\n",
    "                data_list = future.result()\n",
    "                all_data.extend(data_list)\n",
    "            except Exception as exc:\n",
    "                print(f\"Search '{search}' Page {page} generated an exception: {exc}\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "search_term = general.read_sheet(output_sheet, \"search\", 1)\n",
    "search_queries = search_term['search_term'].to_list()\n",
    "start_page = 1\n",
    "end_page = 25\n",
    "\n",
    "all_data = collect_all_data_ids(search_queries, start_page, end_page)\n",
    "print(f\"Total data-id attributes found: {len(all_data)}\")\n",
    "\n",
    "# Create DataFrame\n",
    "search_term_page = pd.DataFrame(all_data, columns=['search_query', 'position', 'page_no', 'data_id'])\n",
    "general.add_sheet_name(output_sheet, 'search_output', 1)\n",
    "general.print_sheet(1, search_term_page, 'search_output', output_sheet, 1, 1, 1)\n",
    "\n",
    "all_fsns = search_term_page['data_id'].to_list()\n",
    "final_fsn_list = list(set(all_fsns))\n",
    "competitor_data = fk_scrapper.scrape_all_fsns(final_fsn_list)\n",
    "competitor_data['brand'] = competitor_data['title'].str.split(\" \").str[0]\n",
    "\n",
    "self = general.read_sheet(output_sheet, sheet_name='self')\n",
    "self_fsn = self['fsn'].to_list()\n",
    "self_data = fk_scrapper.scrape_all_fsns(self_fsn)\n",
    "\n",
    "def convert_to_all_columns(brand_level_data):\n",
    "    # Collect dictionaries for each row in the DataFrame\n",
    "    rows_to_expand = []\n",
    "\n",
    "    for index, row in brand_level_data.iterrows():\n",
    "        specs = row['all_specs']\n",
    "\n",
    "        if not isinstance(specs, dict):\n",
    "            try:\n",
    "                # Attempt to convert if specs is a string representation of a dictionary\n",
    "                specs = ast.literal_eval(specs)\n",
    "            except (ValueError, SyntaxError):\n",
    "                continue\n",
    "\n",
    "        # Only process if it's a valid dictionary\n",
    "        if isinstance(specs, dict):\n",
    "            rows_to_expand.append(pd.Series(specs, name=index))\n",
    "\n",
    "    # Create a new DataFrame from the extracted specs and merge it\n",
    "    if rows_to_expand:\n",
    "        specs_df = pd.DataFrame(rows_to_expand)\n",
    "        brand_level_data = pd.concat([brand_level_data, specs_df], axis=1)\n",
    "\n",
    "    return brand_level_data\n",
    "\n",
    "\n",
    "competitor_data = convert_to_all_columns(competitor_data)\n",
    "self_data = convert_to_all_columns(self_data)\n",
    "competitor_data = competitor_data[competitor_data['ratings_count'] != \"\"]\n",
    "# Create an empty dictionary to store column statistics\n",
    "d = {}\n",
    "\n",
    "# Calculate unique values, percentage of non-null values, and the unique value list for each column\n",
    "for column in competitor_data.columns:\n",
    "    try:\n",
    "        unique_count = competitor_data[column].nunique()\n",
    "        not_na_percentage = competitor_data[column].notna().mean() * 100\n",
    "        unique_values_list = competitor_data[column].dropna().unique().tolist()\n",
    "        d[column] = [unique_count, not_na_percentage, unique_values_list]\n",
    "    except Exception:\n",
    "        competitor_data[column] = competitor_data[column].astype(str)\n",
    "        unique_count = competitor_data[column].nunique()\n",
    "        not_na_percentage = competitor_data[column].notna().mean() * 100\n",
    "        unique_values_list = competitor_data[column].dropna().unique().tolist()\n",
    "        d[column] = [unique_count, not_na_percentage, unique_values_list]\n",
    "\n",
    "\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "column_stats_df = pd.DataFrame.from_dict(d, orient='index', columns=['Unique Values', '% Not NaN', 'Unique Values List'])\n",
    "column_stats_df.reset_index(inplace=True)\n",
    "column_stats_df.rename(columns={'index': 'Column Name'}, inplace=True)\n",
    "\n",
    "df = column_stats_df\n",
    "not_to_consider_columns = [\n",
    "    'productDescription', 'productImagesCount', 'productVideosCount', 'Country of Origin', 'flipkart_assured', 'special_price',\n",
    "    'title', 'rating', 'ratings_count', 'reviews_count', 'Seller Name', 'highlights', 'description', 'specifications', 'reviews',\n",
    "    'image_link', 'all_specs', 'brand', 'Model Name', 'mrp','Model ID'\n",
    "]\n",
    "\n",
    "\n",
    "df = df[(df['Unique Values'] != df['Unique Values'].max()) & (df['Unique Values'] != 1) & (~df['Column Name'].isin(not_to_consider_columns))]\n",
    "\n",
    "def clip_to_max(x):\n",
    "    x=str(x)\n",
    "    if len(x)>49990:\n",
    "        return x[:49990]\n",
    "    else:\n",
    "        return x\n",
    "df['Unique Values List']=df['Unique Values List'].apply(clip_to_max)\n",
    "df=df.sort_values(by='% Not NaN',ascending=False)\n",
    "general.print_sheet(1, df, 'research_of_attributes', output_sheet, 1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "ACCGHMMY5FZJFVZU\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "233\n",
      "ratings_count\n",
      "146\n",
      "Deep Bass\n",
      "137\n",
      "Headphone Design\n",
      "131\n",
      "Brand\n",
      "62\n",
      "ACCGUQDQWBRTU5FU\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "175\n",
      "ratings_count\n",
      "129\n",
      "Deep Bass\n",
      "116\n",
      "Headphone Design\n",
      "116\n",
      "Brand\n",
      "71\n",
      "ACCGJT2ZZGCWCZM3\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGRNFYNKWSPC6D\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "175\n",
      "ratings_count\n",
      "129\n",
      "Deep Bass\n",
      "116\n",
      "Headphone Design\n",
      "116\n",
      "Brand\n",
      "71\n",
      "ACCGPVFTXX9X8TEF\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGXYXKXWPZMGMR\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "175\n",
      "ratings_count\n",
      "129\n",
      "Deep Bass\n",
      "116\n",
      "Headphone Design\n",
      "116\n",
      "Brand\n",
      "71\n",
      "ACCGJHCDF45AFUYY\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGQQ3CZZZSHZJZ\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGHQR9TZY7QZ9B\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGJT2ZVWGQTC8D\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGJHCDXFXZCSWN\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGTDRXMNJXCBBR\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGXY5FXTHHYHAV\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "139\n",
      "ratings_count\n",
      "114\n",
      "Deep Bass\n",
      "101\n",
      "Headphone Design\n",
      "101\n",
      "Brand\n",
      "73\n",
      "ACCGRB6TBHUJ7KTM\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGX2F2QZZH9KUV\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "175\n",
      "ratings_count\n",
      "129\n",
      "Deep Bass\n",
      "116\n",
      "Headphone Design\n",
      "116\n",
      "Brand\n",
      "71\n",
      "ACCG9J7F2NMUB5H6\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGUQDQGEEY4HTX\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "175\n",
      "ratings_count\n",
      "129\n",
      "Deep Bass\n",
      "116\n",
      "Headphone Design\n",
      "116\n",
      "Brand\n",
      "71\n",
      "ACCH2WYBZDGYXUGF\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "130\n",
      "ratings_count\n",
      "88\n",
      "Deep Bass\n",
      "84\n",
      "Headphone Design\n",
      "84\n",
      "Brand\n",
      "60\n",
      "ACCHY2JNQC6EEGWV\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "175\n",
      "ratings_count\n",
      "129\n",
      "Deep Bass\n",
      "116\n",
      "Headphone Design\n",
      "116\n",
      "Brand\n",
      "71\n",
      "ACCGRNFMJ54NCGZ6\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGQ4XWHJWMSZCR\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCHY2J5ZHHMDDZR\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "139\n",
      "ratings_count\n",
      "114\n",
      "Deep Bass\n",
      "101\n",
      "Headphone Design\n",
      "101\n",
      "Brand\n",
      "73\n",
      "ACCGRB6T6ZPSFV2V\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCGS2VSKG3E2JW8\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "114\n",
      "ratings_count\n",
      "98\n",
      "Deep Bass\n",
      "91\n",
      "Headphone Design\n",
      "91\n",
      "Brand\n",
      "66\n",
      "ACCGRNFYJGNPDSTD\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "175\n",
      "ratings_count\n",
      "129\n",
      "Deep Bass\n",
      "116\n",
      "Headphone Design\n",
      "116\n",
      "Brand\n",
      "71\n",
      "ACCGRNFM5GBPUKPF\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCHY2GYZBRKWX7Z\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "114\n",
      "ratings_count\n",
      "98\n",
      "Deep Bass\n",
      "91\n",
      "Headphone Design\n",
      "91\n",
      "Brand\n",
      "66\n",
      "ACCGRB6TD8PTYKFY\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "225\n",
      "ratings_count\n",
      "151\n",
      "Deep Bass\n",
      "141\n",
      "Headphone Design\n",
      "136\n",
      "Brand\n",
      "75\n",
      "ACCHY2GYJUVWXAC9\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "114\n",
      "ratings_count\n",
      "98\n",
      "Deep Bass\n",
      "91\n",
      "Headphone Design\n",
      "91\n",
      "Brand\n",
      "66\n",
      "ACCGGWWZMSTF6BVA\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "130\n",
      "ratings_count\n",
      "88\n",
      "Deep Bass\n",
      "84\n",
      "Headphone Design\n",
      "84\n",
      "Brand\n",
      "60\n",
      "ACCGSZCDZSXEHWW7\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "130\n",
      "ratings_count\n",
      "88\n",
      "Deep Bass\n",
      "84\n",
      "Headphone Design\n",
      "84\n",
      "Brand\n",
      "60\n",
      "ACCGS2VSSPZNZZ5P\n",
      "Headphone Type\n",
      "1426\n",
      "Connectivity\n",
      "1362\n",
      "final_selling_price\n",
      "114\n",
      "ratings_count\n",
      "98\n",
      "Deep Bass\n",
      "91\n",
      "Headphone Design\n",
      "91\n",
      "Brand\n",
      "66\n",
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "uploaded * sheet name *competitor output* in sheet_id *1AZVMYH_qgty_0IT8TtmsCZypWisTn4yOHdCM_JdghG8\n",
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "uploaded * sheet name *self_dump* in sheet_id *1AZVMYH_qgty_0IT8TtmsCZypWisTn4yOHdCM_JdghG8\n",
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "uploaded * sheet name *competitor_dump* in sheet_id *1AZVMYH_qgty_0IT8TtmsCZypWisTn4yOHdCM_JdghG8\n"
     ]
    }
   ],
   "source": [
    "input_df = general.read_sheet(output_sheet, 'attribute', 1)\n",
    "def extract_number(text):\n",
    "    numbers=re.findall(r'\\d+',str(text))\n",
    "    if len(numbers) != 0:\n",
    "        ans=max(numbers)\n",
    "    else:\n",
    "        ans=0\n",
    "    return ans\n",
    "\n",
    "# function is created to format data \n",
    "competitor_data['Brand']=competitor_data['title'].str.split(\" \").str[0]\n",
    "self_data['Brand']=self_data['title'].str.split(\" \").str[0]\n",
    "dynamic_range_vars={}\n",
    "dynamic_categorical_values={}\n",
    "for index,row in input_df.iterrows():\n",
    "    if row['type'] == 'numerical':\n",
    "        if row['range'] == '':\n",
    "            competitor_data[row['column_name']]=competitor_data[row['column_name']].apply(extract_number)\n",
    "            self_data[row['column_name']]=self_data[row['column_name']].apply(extract_number)\n",
    "        if row['range'] != \"\":\n",
    "            try:\n",
    "                \n",
    "                if float(row['range']) <=1:\n",
    "                    # created bounds\n",
    "                    bound_variable=row['column_name']\n",
    "                    range_value=float(row['range'])\n",
    "\n",
    "                    dynamic_range_vars[bound_variable+'_lower_bound']= 1-range_value\n",
    "                    dynamic_range_vars[bound_variable+'_upper_bound'] = 1+range_value\n",
    "                if float(row['range']) >1:\n",
    "                    dynamic_range_vars[row['column_name']+'_greater_than'] = row['range']\n",
    "            except:\n",
    "                \n",
    "                value=[int(i.strip()) for i in  row['range'].split(\",\")]\n",
    "                value.append(np.inf)\n",
    "                new_column=row['column_name']+'_bin'\n",
    "                try:\n",
    "                    competitor_data[row['column_name']]=competitor_data[row['column_name']].apply(extract_number)\n",
    "                    self_data[row['column_name']]=self_data[row['column_name']].apply(extract_number)\n",
    "                except:\n",
    "                    pass\n",
    "                print(new_column)\n",
    "                competitor_data=competitor_data[competitor_data[row['column_name']] != \"\"]\n",
    "                competitor_data[row['column_name']]=competitor_data[row['column_name']].astype('float')\n",
    "                competitor_data[new_column]=pd.cut(competitor_data[row['column_name']],bins=value)\n",
    "                competitor_data[new_column]=pd.cut(competitor_data[row['column_name']],bins=value)\n",
    "\n",
    "                self_data=self_data[self_data[row['column_name']] != \"\"]\n",
    "                self_data[row['column_name']]=self_data[row['column_name']].astype('float')\n",
    "                self_data[new_column]=pd.cut(self_data[row['column_name']],bins=value)\n",
    "                self_data[new_column]=pd.cut(self_data[row['column_name']],bins=value)\n",
    "\n",
    "            competitor_data=competitor_data[competitor_data[row['column_name']] != \"\"]\n",
    "            competitor_data[row['column_name']]=competitor_data[row['column_name']].astype('float')\n",
    "\n",
    "    elif row['type'] == 'categorical':\n",
    "        if row['range'] == '':\n",
    "            dynamic_categorical_values[row['column_name']] = 'exact'\n",
    "        else:\n",
    "            values=[i.strip() for i in row['range'].split(\",\")]\n",
    "            dynamic_categorical_values[row['column_name']] = values\n",
    "\n",
    "self_data=self_data[self_data['final_selling_price'] != \"\"]\n",
    "\n",
    "final_df_list=[]\n",
    "for self_index,self_row in self_data.iterrows():\n",
    "    print(self_row['fsn'])\n",
    "    temp=competitor_data.copy()\n",
    "    for input_index,input_row in input_df.iterrows():\n",
    "        process=input_row['column_name']\n",
    "        print(process)\n",
    "\n",
    "\n",
    "    # for comp_index,comp_row in competitor_data.iterrows():\n",
    "        if input_row['type'] == 'numerical':\n",
    "            if input_row['range'] == '':\n",
    "                # range_bin_column=input_row['column_name']+'_bin'\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    if float(input_row['range'])<=1:\n",
    "                        range_column=input_row['column_name']\n",
    "                        lower_range=dynamic_range_vars[f'{range_column}_lower_bound']*self_row[input_row['column_name']]\n",
    "                        upper_range=dynamic_range_vars[f'{range_column}_upper_bound']*self_row[input_row['column_name']]\n",
    "                        temp=temp[(temp[range_column]>=lower_range) &(temp[range_column]<=upper_range) ]\n",
    "                        temp.insert(1, f'self_{range_column}', self_row[range_column])\n",
    "                        print(len(temp))\n",
    "                    if float(input_row['range'])>=1:\n",
    "                        greater_than_column=input_row['column_name']\n",
    "                        temp=temp[temp[greater_than_column] > input_row['range']]\n",
    "                        temp.insert(1, f'self_{greater_than_column}', self_row[greater_than_column])\n",
    "                        print(len(temp))\n",
    "                except:\n",
    "                    to_insert=input_row['column_name']\n",
    "                    range_bin_column=input_row['column_name']+'_bin'\n",
    "                    temp=temp[temp[range_bin_column]==self_row[range_bin_column]]\n",
    "                    temp.insert(1, f'self_{to_insert}', self_row[to_insert])\n",
    "                    \n",
    "                    print(len(temp))\n",
    "        elif input_row['type'] == 'categorical':\n",
    "            if input_row['range'] == '':\n",
    "                \n",
    "                categorical_exact_column=input_row['column_name']\n",
    "                if self_row[categorical_exact_column] is not None:\n",
    "                    temp=temp[(temp[categorical_exact_column] == self_row[categorical_exact_column])|(temp[categorical_exact_column] == None)]\n",
    "                    temp.insert(1, f'self_{categorical_exact_column}', self_row[categorical_exact_column])\n",
    "                    print(len(temp))\n",
    "            else:\n",
    "                categorical_list_column=input_row['column_name']\n",
    "                if self_row[categorical_list_column] is not None:\n",
    "                    temp=temp[temp[categorical_list_column].isin(dynamic_categorical_values[categorical_list_column])]\n",
    "                    temp.insert(1, f'self_{categorical_list_column}', self_row[categorical_list_column])\n",
    "                    print(len(temp))\n",
    "\n",
    "        temp=temp[temp['Brand']!= self_row['Brand']]\n",
    "\n",
    "\n",
    "    if not temp.empty:\n",
    "        temp.insert(0, 'self_fsn', self_row['fsn'])\n",
    "        temp.insert(1, 'self_price', self_row['final_selling_price'])\n",
    "        temp.rename({\"fsn\": \"competitor_fsn\"}, axis=1, inplace=True)\n",
    "        final_df_list.append(temp)\n",
    "\n",
    "if final_df_list:\n",
    "    final_df = pd.concat(final_df_list, ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.DataFrame() \n",
    "\n",
    "# Convert all categorical columns to strings\n",
    "final_df = final_df.astype({col: 'string' for col in final_df.select_dtypes(['category']).columns})\n",
    "\n",
    "# Check if NaNs still exist and fill them with an empty string\n",
    "final_df = final_df.fillna(' ')\n",
    "try:\n",
    "    final_df['Net Quantity']=final_df['Net Quantity'].astype(float)\n",
    "    final_df['self_Total no of Pieces']=final_df['self_Total no of Pieces'].astype(float)\n",
    "    final_df['per_unit_competitor_price']=final_df['final_selling_price']/final_df['Net Quantity']\n",
    "    final_df['per_unit_self_price']=final_df['self_final_selling_price']/final_df['self_Total no of Pieces']\n",
    "except:\n",
    "    pass\n",
    "# Now call your function to print to the sheet\n",
    "general.add_sheet_name(output_sheet,'competitor output',1)\n",
    "general.print_sheet(1, final_df, 'competitor output', output_sheet, 1, 1, 1)\n",
    "self_data = self_data.astype({col: 'string' for col in self_data.select_dtypes(['category']).columns})\n",
    "competitor_data = competitor_data.astype({col: 'string' for col in competitor_data.select_dtypes(['category']).columns})\n",
    "# Check if NaNs still exist and fill them with an empty string\n",
    "self_data = self_data.fillna(' ')\n",
    "competitor_data = competitor_data.fillna(' ')\n",
    "general.add_sheet_name(output_sheet,'self_dump',1)\n",
    "general.print_sheet(1, self_data, 'self_dump', output_sheet, 1, 1, 1)\n",
    "general.add_sheet_name(output_sheet,'competitor_dump',1)\n",
    "general.print_sheet(1, competitor_data, 'competitor_dump', output_sheet, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
