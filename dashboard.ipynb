{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "Total data-id attributes found: 4116\n",
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "uploaded * sheet name *search_output* in sheet_id *1vBoQA3yxu6glukkFO5ohaYgQeIQ5X3TAVY-dm9BwM0o\n"
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "from urllib.parse import urlencode\n",
    "from bs4 import BeautifulSoup\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import io\n",
    "from scrapper import flipkart_json_scrapper_with_all_specifications as fk_scrapper\n",
    "from piTask import general\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "# Thread-local data to store per-thread HTTPSConnection\n",
    "thread_local = threading.local()\n",
    "output_sheet='1vBoQA3yxu6glukkFO5ohaYgQeIQ5X3TAVY-dm9BwM0o'\n",
    "def get_connection():\n",
    "    if not hasattr(thread_local, 'conn'):\n",
    "        thread_local.conn = http.client.HTTPSConnection(\"www.flipkart.com\", timeout=10)\n",
    "    return thread_local.conn\n",
    "\n",
    "def get_fsn(search, page):\n",
    "    params = {\n",
    "        'q': search,\n",
    "        'page': page\n",
    "    }\n",
    "    query_string = urlencode(params)\n",
    "    path = f\"/search?{query_string}\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                      'Chrome/85.0.4183.102 Safari/537.36',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Connection': 'keep-alive',\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        conn.request(\"GET\", path, headers=headers)\n",
    "        res = conn.getresponse()\n",
    "        if res.status != 200:\n",
    "            print(f\"Error fetching page {page} for search '{search}': {res.status} {res.reason}\")\n",
    "            res.close()\n",
    "            return []\n",
    "        data = res.read()\n",
    "        res.close()\n",
    "\n",
    "        # Handle gzip encoding if present\n",
    "        encoding = res.getheader('Content-Encoding')\n",
    "        if encoding == 'gzip':\n",
    "            buf = io.BytesIO(data)\n",
    "            f = gzip.GzipFile(fileobj=buf)\n",
    "            data = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "        elements_with_data_id = soup.find_all(attrs={'data-id': True})\n",
    "        data_list = []\n",
    "        for position, element in enumerate(elements_with_data_id, start=1):\n",
    "            data_id = element['data-id']\n",
    "            data_list.append({\n",
    "                'search_query': search,\n",
    "                'position': position,\n",
    "                'page_no': page,\n",
    "                'data_id': data_id\n",
    "            })\n",
    "\n",
    "        return data_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in get_fsn for search '{search}' page {page}: {e}\")\n",
    "        return []\n",
    "\n",
    "def collect_all_data_ids(search_queries, start_page, end_page):\n",
    "    all_data = []\n",
    "    tasks = [(search, page) for search in search_queries for page in range(start_page, end_page + 1)]\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        future_to_task = {executor.submit(get_fsn, search, page): (search, page) for (search, page) in tasks}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_task):\n",
    "            search, page = future_to_task[future]\n",
    "            try:\n",
    "                data_list = future.result()\n",
    "\n",
    "                all_data.extend(data_list)\n",
    "            except Exception as exc:\n",
    "                print(f\"Search '{search}' Page {page} generated an exception: {exc}\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "search_term=general.read_sheet(output_sheet,\"search\",1)\n",
    "search_queries=search_term['search_term'].to_list()\n",
    "start_page = 1\n",
    "end_page = 25\n",
    "\n",
    "all_data = collect_all_data_ids(search_queries, start_page, end_page)\n",
    "print(f\"Total data-id attributes found: {len(all_data)}\")\n",
    "\n",
    "# Create DataFrame\n",
    "search_term_page = pd.DataFrame(all_data, columns=['search_query', 'position', 'page_no', 'data_id'])\n",
    "\n",
    "general.print_sheet(1,search_term_page,'search_output',output_sheet,1,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded * sheet name *competitor output* in sheet_id *1vBoQA3yxu6glukkFO5ohaYgQeIQ5X3TAVY-dm9BwM0o\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_fsns = search_term_page['data_id'].to_list()\n",
    "final_fsn_list = list(set(all_fsns))\n",
    "competitor_data=fk_scrapper.scrape_all_fsns(final_fsn_list)\n",
    "competitor_data['brand'] = competitor_data['title'].str.split(\" \").str[0]\n",
    "\n",
    "self=general.read_sheet(output_sheet,sheet_name='self')\n",
    "self_fsn=self['fsn'].to_list()\n",
    "self_data=fk_scrapper.scrape_all_fsns(self_fsn)\n",
    "\n",
    "\n",
    "def convert_to_all_columns(brand_level_data):\n",
    "    for index, row in brand_level_data.iterrows():\n",
    "        specs = row['all_specs']\n",
    "\n",
    "        if not isinstance(specs, dict):\n",
    "            try:\n",
    "                # Attempt to convert if specs is a string representation of a dictionary\n",
    "                specs = ast.literal_eval(specs)\n",
    "            except (ValueError, SyntaxError):\n",
    "                # If conversion fails, skip processing this row\n",
    "                continue\n",
    "\n",
    "        # Process dictionary and update the DataFrame\n",
    "        if isinstance(specs, dict):\n",
    "            for key, value in specs.items():\n",
    "                if key not in brand_level_data.columns:\n",
    "                    brand_level_data[key] = None  # Add new column if it doesn't exist\n",
    "                brand_level_data.at[index, key] = value\n",
    "\n",
    "    return brand_level_data\n",
    "competitor_data=convert_to_all_columns(competitor_data)\n",
    "self_data=convert_to_all_columns(self_data)\n",
    "competitor_data=competitor_data[competitor_data['ratings_count'] != \"\"]\n",
    "\n",
    "\n",
    "# Create an empty dictionary to store column statistics\n",
    "d = {}\n",
    "\n",
    "# Calculate unique values, percentage of non-null values, and the unique value list for each column\n",
    "for column in competitor_data.columns:\n",
    "    try:\n",
    "        unique_count = competitor_data[column].nunique()\n",
    "        not_na_percentage = competitor_data[column].notna().mean() * 100\n",
    "        unique_values_list = competitor_data[column].unique().tolist()  # Get the list of unique values\n",
    "        d[column] = [unique_count, not_na_percentage, unique_values_list]\n",
    "\n",
    "    except:\n",
    "        # Handle errors by converting the column to string type\n",
    "        competitor_data[column] = competitor_data[column].astype(str)\n",
    "        unique_count = competitor_data[column].nunique()\n",
    "        not_na_percentage = competitor_data[column].notna().mean() * 100\n",
    "        unique_values_list = competitor_data[column].unique().tolist()  # Get the list of unique values\n",
    "        d[column] = [unique_count, not_na_percentage, unique_values_list]\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "column_stats_df = pd.DataFrame.from_dict(d, orient='index', columns=['Unique Values', '% Not NaN', 'Unique Values List'])\n",
    "column_stats_df.reset_index(inplace=True)\n",
    "column_stats_df.rename(columns={'index': 'Column Name'}, inplace=True)\n",
    "\n",
    "df=column_stats_df.sort_values(\"% Not NaN\",ascending=False)\n",
    "not_to_consider_columns=['productDescription','productImagesCount','productVideosCount','Country of Origin','flipkart_assured','special_price',\n",
    "                         'title','rating','ratings_count','reviews_count','Seller Name','highlights','description','specifications','reviews',\n",
    "                         'image_link','all_specs','brand','Model Name','mrp']\n",
    "df=df[(df['Unique Values'] != df['Unique Values'].max())& (df['Unique Values'] !=1)& (~df['Column Name'].isin(not_to_consider_columns))]\n",
    "general.print_sheet(1,df,'research_of_attributes',output_sheet,1,1,1)\n",
    "input_df=general.read_sheet(output_sheet,'attribute',1)\n",
    "\n",
    "def extract_number(text):\n",
    "    numbers=re.findall(r'\\d+',str(text))\n",
    "    if len(numbers) != 0:\n",
    "        ans=max(numbers)\n",
    "    else:\n",
    "        ans=0\n",
    "    return ans\n",
    "\n",
    "# function is created to format data \n",
    "dynamic_range_vars={}\n",
    "dynamic_categorical_values={}\n",
    "for index,row in input_df.iterrows():\n",
    "    if row['type'] == 'numerical':\n",
    "        if row['range'] == '':\n",
    "            competitor_data[row['column_name']]=competitor_data[row['column_name']].apply(extract_number)\n",
    "            self_data[row['column_name']]=self_data[row['column_name']].apply(extract_number)\n",
    "        if row['range'] != \"\":\n",
    "            try:\n",
    "                \n",
    "                if float(row['range']) <=1:\n",
    "                    # created bounds\n",
    "                    bound_variable=row['column_name']\n",
    "                    range_value=float(row['range'])\n",
    "\n",
    "                    dynamic_range_vars[bound_variable+'_lower_bound']= 1-range_value\n",
    "                    dynamic_range_vars[bound_variable+'_upper_bound'] = 1+range_value\n",
    "                if float(row['range']) >1:\n",
    "                    dynamic_range_vars[row['column_name']+'_greater_than'] = row['range']\n",
    "            except:\n",
    "                \n",
    "                value=[int(i.strip()) for i in  row['range'].split(\",\")]\n",
    "                value.append(np.inf)\n",
    "                new_column=row['column_name']+'_bin'\n",
    "                try:\n",
    "                    competitor_data[row['column_name']]=competitor_data[row['column_name']].apply(extract_number)\n",
    "                    self_data[row['column_name']]=self_data[row['column_name']].apply(extract_number)\n",
    "                except:\n",
    "                    pass\n",
    "                print(new_column)\n",
    "                competitor_data=competitor_data[competitor_data[row['column_name']] != \"\"]\n",
    "                competitor_data[row['column_name']]=competitor_data[row['column_name']].astype('float')\n",
    "                competitor_data[new_column]=pd.cut(competitor_data[row['column_name']],bins=value)\n",
    "                competitor_data[new_column]=pd.cut(competitor_data[row['column_name']],bins=value)\n",
    "\n",
    "                self_data=self_data[self_data[row['column_name']] != \"\"]\n",
    "                self_data[row['column_name']]=self_data[row['column_name']].astype('float')\n",
    "                self_data[new_column]=pd.cut(self_data[row['column_name']],bins=value)\n",
    "                self_data[new_column]=pd.cut(self_data[row['column_name']],bins=value)\n",
    "\n",
    "            competitor_data=competitor_data[competitor_data[row['column_name']] != \"\"]\n",
    "            competitor_data[row['column_name']]=competitor_data[row['column_name']].astype('float')\n",
    "\n",
    "    elif row['type'] == 'categorical':\n",
    "        if row['range'] == '':\n",
    "            dynamic_categorical_values[row['column_name']] = 'exact'\n",
    "        else:\n",
    "            values=[i.strip() for i in row['range'].split(\",\")]\n",
    "            dynamic_categorical_values[row['column_name']] = values\n",
    "\n",
    "self_data=self_data[self_data['final_selling_price'] != \"\"]\n",
    "\n",
    "final_df_list=[]\n",
    "for self_index,self_row in self_data.iterrows():\n",
    "    print(self_row['fsn'])\n",
    "    temp=competitor_data.copy()\n",
    "    for input_index,input_row in input_df.iterrows():\n",
    "        process=input_row['column_name']\n",
    "        print(process)\n",
    "\n",
    "\n",
    "    # for comp_index,comp_row in competitor_data.iterrows():\n",
    "        if input_row['type'] == 'numerical':\n",
    "            if input_row['range'] == '':\n",
    "                # range_bin_column=input_row['column_name']+'_bin'\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    if float(input_row['range'])<=1:\n",
    "                        range_column=input_row['column_name']\n",
    "                        lower_range=dynamic_range_vars[f'{range_column}_lower_bound']*self_row[input_row['column_name']]\n",
    "                        upper_range=dynamic_range_vars[f'{range_column}_upper_bound']*self_row[input_row['column_name']]\n",
    "                        temp=temp[(temp[range_column]>=lower_range) &(temp[range_column]<=upper_range) ]\n",
    "                        temp.insert(1, f'self_{range_column}', self_row[range_column])\n",
    "                        print(len(temp))\n",
    "                    if float(input_row['range'])>=1:\n",
    "                        greater_than_column=input_row['column_name']\n",
    "                        temp=temp[temp[greater_than_column] > input_row['range']]\n",
    "                        temp.insert(1, f'self_{greater_than_column}', self_row[greater_than_column])\n",
    "                        print(len(temp))\n",
    "                except:\n",
    "                    to_insert=input_row['column_name']\n",
    "                    range_bin_column=input_row['column_name']+'_bin'\n",
    "                    temp=temp[temp[range_bin_column]==self_row[range_bin_column]]\n",
    "                    temp.insert(1, f'self_{to_insert}', self_row[to_insert])\n",
    "                    \n",
    "                    print(len(temp))\n",
    "        elif input_row['type'] == 'categorical':\n",
    "            if input_row['range'] == '':\n",
    "                \n",
    "                categorical_exact_column=input_row['column_name']\n",
    "                if self_row[categorical_exact_column] is not None:\n",
    "                    temp=temp[(temp[categorical_exact_column] == self_row[categorical_exact_column])|(temp[categorical_exact_column] == None)]\n",
    "                    temp.insert(1, f'self_{categorical_exact_column}', self_row[categorical_exact_column])\n",
    "                    print(len(temp))\n",
    "            else:\n",
    "                categorical_list_column=input_row['column_name']\n",
    "                if self_row[categorical_list_column] is not None:\n",
    "                    temp=temp[temp[categorical_list_column].isin(dynamic_categorical_values[categorical_list_column])]\n",
    "                    temp.insert(1, f'self_{categorical_list_column}', self_row[categorical_list_column])\n",
    "                    print(len(temp))\n",
    "        temp=temp[temp['Brand']!= self_row['Brand']]\n",
    "\n",
    "    if not temp.empty:\n",
    "        temp.insert(0, 'self_fsn', self_row['fsn'])\n",
    "        temp.insert(1, 'self_price', self_row['final_selling_price'])\n",
    "        temp.rename({\"fsn\": \"competitor_fsn\"}, axis=1, inplace=True)\n",
    "        final_df_list.append(temp)\n",
    "\n",
    "if final_df_list:\n",
    "    final_df = pd.concat(final_df_list, ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.DataFrame() \n",
    "\n",
    "# Convert all categorical columns to strings\n",
    "final_df = final_df.astype({col: 'string' for col in final_df.select_dtypes(['category']).columns})\n",
    "\n",
    "# Check if NaNs still exist and fill them with an empty string\n",
    "final_df = final_df.fillna(' ')\n",
    "try:\n",
    "    final_df['Net Quantity']=final_df['Net Quantity'].astype(float)\n",
    "    final_df['self_Total no of Pieces']=final_df['self_Total no of Pieces'].astype(float)\n",
    "    final_df['per_unit_competitor_price']=final_df['final_selling_price']/final_df['Net Quantity']\n",
    "    final_df['per_unit_self_price']=final_df['self_final_selling_price']/final_df['self_Total no of Pieces']\n",
    "except:\n",
    "    pass\n",
    "# Now call your function to print to the sheet\n",
    "general.print_sheet(1, final_df, 'competitor output', output_sheet, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_columns=['final_selling_price','Total no of Pieces',]\n",
    "\n",
    "# categorical_columns=['Ideal For','Water Resistant','Headphone Design']\n",
    "# to_be_processed=numerical_columns+categorical_columns\n",
    "# def get_all_columns(df):\n",
    "#     def list_to_string(x):\n",
    "#         if isinstance(x, list):\n",
    "#             return ', '.join(map(str, x))\n",
    "#         elif pd.isnull(x):  # Handle NaN values if any\n",
    "#             return ''\n",
    "#         else:\n",
    "#             return str(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # Data processing\n",
    "#     df['brand'] = df['title'].str.split(\" \").str[0]\n",
    "#     brand_level_data = df.copy()\n",
    "#     brand_level_data['highlights'] = brand_level_data['highlights'].apply(list_to_string)\n",
    "\n",
    "#     # Ensure 'fsn' and 'brand' are included\n",
    "#     required_columns = ['fsn', 'brand']\n",
    "#     for col in required_columns:\n",
    "#         if col in brand_level_data.columns and col not in brand_level_data.columns:\n",
    "#             brand_level_data[col] = df[col]\n",
    "\n",
    "\n",
    "#     # Expand 'all_specs' into separate columns\n",
    "#     for index, row in brand_level_data.iterrows():\n",
    "#         specs = row['all_specs']\n",
    "#         if isinstance(specs, dict):\n",
    "#             for key, value in specs.items():\n",
    "#                 if key not in brand_level_data.columns:\n",
    "#                     brand_level_data[key] = None\n",
    "#                 brand_level_data.at[index, key] = value\n",
    "#     return brand_level_data\n",
    "# def process_columns(df):\n",
    "#     for column in df.columns:\n",
    "#         if column in numerical_columns:\n",
    "#             if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "#                 df[column] = df[column].astype(str)\n",
    "#                 df[column] = df[column].str.extract(r'(\\d+,\\d+\\.\\d+|\\d+,\\d+|\\d+\\.\\d+|\\d+)', expand=False)\n",
    "#                 df[column] = df[column].astype(str)\n",
    "#                 df[column] = df[column].str.replace(',', '')\n",
    "#                 df[column] = df[column].astype(float)\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self_data=get_all_columns(self_data)\n",
    "# competitor_data=get_all_columns(competitor_data)\n",
    "# # competitor_data=process_columns(competitor_data)\n",
    "# # self_data=process_columns(self_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\personal_git\\data science\\portfolio projects\\Competition analysis\\key1.json\n",
      "uploaded * sheet name *research_of_attributes* in sheet_id *1vBoQA3yxu6glukkFO5ohaYgQeIQ5X3TAVY-dm9BwM0o\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
